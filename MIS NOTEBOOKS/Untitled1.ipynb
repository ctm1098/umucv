{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05970987",
   "metadata": {},
   "source": [
    "# EJERCICIO SIFT\n",
    "\n",
    "Para la resolución de este ejercicio se propone el código del *script* ```calibrate.py```, el cual puede encontrarse el mismo directorio que este *notebook*. Este *script* se trata de una aplicación reconocimiento de objetos con la *webcam* basada en el número de coincidencias de *keypoints*. Estos *keypoints* no son más que características relevantes de las imágenes que pueden usarse para el reconocimiento de las mismas. Para la extracción de estos puntos, se emplea el algoritmo SIFT, siendo el número de características un valor parametrizable al gusto del usuario. El usuario será capaz de suministrar a la aplicación unos modelos en formato *jpg* ya creados con anterioridad y/o capturar modelos al vuelo con la *webcam*.\n",
    "\n",
    "Comenzamos con la importación de las librerías requeridas y la definición de ciertas macros y una función auxiliar, *fillborders*, que únicamente se encarga de dibujar los bordes con un color gris en el frame para enmarcar el modelo detectado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6cd8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2        as cv\n",
    "import numpy      as np\n",
    "from glob         import glob\n",
    "from umucv.stream import Camera\n",
    "from umucv.util   import putText\n",
    "from math         import floor\n",
    "\n",
    "\n",
    "def fillborders(frame,model,x_offset,y_offset,col):\n",
    "    frame[y_offset:y_offset+model.shape[0],0:x_offset] = col\n",
    "    frame[y_offset:y_offset+model.shape[0],x_offset+model.shape[1]:2*x_offset+model.shape[1]] = col\n",
    "    frame[y_offset-x_offset:y_offset,0:2*x_offset+model.shape[1]] = col\n",
    "    frame[y_offset+model.shape[0]:y_offset+x_offset+model.shape[0],0:2*x_offset+model.shape[1]] = col\n",
    "\n",
    "NFEATURES = 500  #El numero de keypoints\n",
    "WH = '640x480'  #Las dimensiones del frame\n",
    "THRES = 7  #El valor umbral de coincidencias\n",
    "MODELS_PATH = './SIFT-models/*.jpg'  #El path hacia los modelos jpg\n",
    "    \n",
    "W,H = (int(WH.split('x')[0]), int(WH.split('x')[1]))   \n",
    "\n",
    "if W <= 0 or H <= 0:\n",
    "    print('Frame dimensions must be positive integers')\n",
    "    exit()\n",
    "\n",
    "# Ancho y alto del mini-modelo que solaparemos en el frame original cuando se detecte\n",
    "modelW,modelH = (floor(W/4.18), floor(H/3.42))\n",
    "# Offsets para el mini-modelo para solaparlo en el frame\n",
    "x_offset=10\n",
    "y_offset=40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bb731",
   "metadata": {},
   "source": [
    "A continuación, en caso de que el usuario haya decidido usar sus propios modelos, recorremos el directorio indicado y guardamos en una lista los modelos con las dimensiones indicadas en el bloque de código anterior (vale la pena mencionar que las dimensiones de un modelo y de un frame serán las mismas para garantizar una ejecución más precisa del algoritmo SIFT). Por cada modelo leído, lo almacenamos junto con su nombre y *keypoints* y descriptores que nos proporciona la función ```detectAndCompute``` de SIFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d814a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv.xfeatures2d.SIFT_create(nfeatures=NFEATURES)\n",
    "models = []\n",
    "files = glob(MODELS_PATH)\n",
    "for f in files:\n",
    "    name = f.split('\\\\')[-1].split('.')[0].replace('_',' ')\n",
    "    model = cv.resize(cv.imread(f),(W,H))\n",
    "    kpts, descs = sift.detectAndCompute(model,None)\n",
    "    models.append((name,model,kpts,descs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e8dc9",
   "metadata": {},
   "source": [
    "A continuación hacemos uso de la utilidad ```Camera``` de ```umucv``` para la captura de *frames* con hilo. Entramos en un bucle infinito en el que procesamos en cada iteración un *frame*. En cada iteración comprobamos también qué tecla se ha pulsado, cada una mapeándose a las siguientes acciones:\n",
    "\n",
    "- **ESC** para terminar con el procesamiento.\n",
    "- **X** para vaciar la colección de modelos.\n",
    "- **C** para guardar el *frame* actual como modelo. Se actualiza un contador *idx* que se incluye en el nombre para poder distinguir estos modelos capturados en tiempo de ejecución.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "cv.namedWindow(\"camera\")\n",
    "cam = Camera(size = (W,H))\n",
    "idx = 0\n",
    "match = cv.BFMatcher()\n",
    "\n",
    "while True:\n",
    "    frame = cam.frame.copy()\n",
    "    \n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == 27: \n",
    "        break\n",
    "\n",
    "    if key == ord('x'):\n",
    "        models.clear()\n",
    "\n",
    "    if key in [ord('c'), ord('C')]:\n",
    "        model = frame.copy()\n",
    "        kpts, descs = sift.detectAndCompute(model,None)\n",
    "        models.append((\"Model_{}\".format(idx),model,kpts,descs))\n",
    "        idx+=1\n",
    "        print(\"Added model {}\".format(idx))\n",
    "        \n",
    "   \n",
    "    # ...\n",
    "\n",
    "```\n",
    "\n",
    "Posteriormente, si disponemos de modelos, realizamos la comparación del *frame* actual con los modelos disponibles. La comparativa debe superar un umbral de coincidencia *THRES* para que el modelo se considere aceptable. Las coincidencias de *keypoints* entre el *frame* actual y el modelo se calculan con el método de ***k-nearest neigbors*** del *matcher* y luego se filtran para dejar solo las que que no tengan ambigüedad. La forma en la que se realiza esto es usando el *ratio test*: se descartan los puntos cuya mejor coincidencia es parecida a la segunda mejor (más concretamente, si no se distingue, como mínimo, en un 85%).\n",
    "\n",
    "```python\n",
    "    if models:\n",
    "            #and key in [ord('e'), ord('E')]\n",
    "\n",
    "            frame_kpts, frame_descs = sift.detectAndCompute(frame, mask=None)\n",
    "\n",
    "            modelDetected = np.zeros((modelW,modelW,3),dtype = \"uint8\")\n",
    "            best_name = 'None'\n",
    "            max = 0\n",
    "            for (name,model,model_kpts,model_descs) in models:\n",
    "                pts = []\n",
    "\n",
    "                matches = match.knnMatch(frame_descs,model_descs,k=2)\n",
    "\n",
    "                #ratio test\n",
    "                for m in matches:\n",
    "                    if len(m) >= 2:\n",
    "                        best,second = m\n",
    "                        if best.distance < 0.85*second.distance:\n",
    "                            pts.append(best)\n",
    "\n",
    "                percent = 100*len(pts)/len(model_kpts)\n",
    "\n",
    "                #Nos quedamos con el mejor modelo\n",
    "                if (percent > max):\n",
    "                    bestModel = (name,model)\n",
    "                    max = percent\n",
    "\n",
    "            #Si el porcentaje de coincidencias supera el umbral establecido, se considera el modelo\n",
    "            if (percent > THRES):\n",
    "                (name,model) = bestModel\n",
    "                modelDetected = cv.resize(model.copy(), (modelW,modelW))\n",
    "                best_name = name\n",
    "\n",
    "            #Insertamos el modelo detectado en el frame junto con la informacion de coincidencias\n",
    "            putText(frame, f'{len(frame_kpts)} pts')\n",
    "            fillborders(frame,modelDetected,x_offset,y_offset,col = (192,192,192))\n",
    "            frame[y_offset:y_offset+modelDetected.shape[0], x_offset:x_offset+modelDetected.shape[1]] = modelDetected\n",
    "            putText(frame, f'{percent:.2f}% likelihood', orig = (x_offset,y_offset+modelDetected.shape[0]+30))\n",
    "            putText(frame, f'{best_name}', orig = (x_offset,y_offset+modelDetected.shape[0]+60))\n",
    "\n",
    "    #flag = cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "    #cv.drawKeypoints(frame, frame_kpts, frame, color=(100,150,255), flags=flag)\n",
    "    cv.imshow('camera',frame)\n",
    "\n",
    "cam.stop()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff2605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640x480 30.0fps\n",
      "Added model 1\n",
      "Added model 2\n"
     ]
    }
   ],
   "source": [
    "cv.namedWindow(\"camera\")\n",
    "cam = Camera(size = (W,H))\n",
    "idx = 0\n",
    "match = cv.BFMatcher()\n",
    "\n",
    "while True:\n",
    "    frame = cam.frame.copy()\n",
    "    \n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == 27: \n",
    "        break\n",
    "\n",
    "    if key == ord('x'):\n",
    "        models.clear()\n",
    "\n",
    "    if key in [ord('c'), ord('C')]:\n",
    "        model = frame.copy()\n",
    "        kpts, descs = sift.detectAndCompute(model,None)\n",
    "        models.append((\"Model_{}\".format(idx),model,kpts,descs))\n",
    "        idx+=1\n",
    "        print(\"Added model {}\".format(idx))\n",
    "        \n",
    "    if models:\n",
    "            #and key in [ord('e'), ord('E')]\n",
    "\n",
    "            frame_kpts, frame_descs = sift.detectAndCompute(frame, mask=None)\n",
    "\n",
    "            modelDetected = np.zeros((modelW,modelW,3),dtype = \"uint8\")\n",
    "            best_name = 'None'\n",
    "            max = 0\n",
    "            for (name,model,model_kpts,model_descs) in models:\n",
    "                pts = []\n",
    "\n",
    "                matches = match.knnMatch(frame_descs,model_descs,k=2)\n",
    "\n",
    "                #ratio test\n",
    "                for m in matches:\n",
    "                    if len(m) >= 2:\n",
    "                        best,second = m\n",
    "                        if best.distance < 0.85*second.distance:\n",
    "                            pts.append(best)\n",
    "\n",
    "                percent = 100*len(pts)/len(model_kpts)\n",
    "\n",
    "                #Nos quedamos con el mejor modelo\n",
    "                if (percent > max):\n",
    "                    bestModel = (name,model)\n",
    "                    max = percent\n",
    "\n",
    "            #Si el porcentaje de coincidencias supera el umbral establecido, se considera el modelo\n",
    "            if (percent > THRES):\n",
    "                (name,model) = bestModel\n",
    "                modelDetected = cv.resize(model.copy(), (modelW,modelW))\n",
    "                best_name = name\n",
    "\n",
    "            #Insertamos el modelo detectado en el frame junto con la informacion de coincidencias\n",
    "            putText(frame, f'{len(frame_kpts)} pts')\n",
    "            fillborders(frame,modelDetected,x_offset,y_offset,col = (192,192,192))\n",
    "            frame[y_offset:y_offset+modelDetected.shape[0], x_offset:x_offset+modelDetected.shape[1]] = modelDetected\n",
    "            putText(frame, f'{percent:.2f}% likelihood', orig = (x_offset,y_offset+modelDetected.shape[0]+30))\n",
    "            putText(frame, f'{best_name}', orig = (x_offset,y_offset+modelDetected.shape[0]+60))\n",
    "\n",
    "    #flag = cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "    #cv.drawKeypoints(frame, frame_kpts, frame, color=(100,150,255), flags=flag)\n",
    "    cv.imshow('camera',frame)\n",
    "\n",
    "cam.stop()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e5d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
